{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "fmt = '%(asctime)s : %(levelname)s : %(message)s'\n",
    "logging.basicConfig(format=fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/masthesis/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 2969591811\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gzip.open('data/paper-round-3/event-annotated/auto-sample.csv.gz', 'rt') as f:\n",
    "    dat = pd.read_csv(f, parse_dates=['timestamp'], index_col='id')\n",
    "\n",
    "assert dat.index.is_unique\n",
    "\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gzip.open('data/paper-round-3/event-annotated/auto-sample-communities-merged-pre-filter.csv.gz', 'rt') as f:\n",
    "    comms = pd.read_csv(f, index_col='id')\n",
    "\n",
    "assert comms.index.is_unique\n",
    "assert comms['year'].isna().sum() == 0\n",
    "\n",
    "comms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat['group'] = comms['group']\n",
    "has_group_mask = dat['group'].notna()\n",
    "dat = dat.loc[has_group_mask, :]\n",
    "\n",
    "dat['group'] = dat['group'].astype(int)\n",
    "dat['year'] = dat['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average embeddings by community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/paper-round-3/event-annotated/auto-sample-mean-embs-uniques.pkl', 'rb') as f:\n",
    "    all_uniques, all_mean_embs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask out comparisons we don't want\n",
    "\n",
    "We want stories that overlap in time (incl being in the same year) and are from different media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = all_uniques['start'].astype(np.int64) // 10**9\n",
    "start = np.expand_dims(start.to_numpy(), axis=-1)\n",
    "\n",
    "end = all_uniques['end'].astype(np.int64) // 10**9\n",
    "end = np.expand_dims(end.to_numpy(), axis=-1)\n",
    "\n",
    "time_mask = (start.T < end) & (end.T > start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = all_uniques['year'].astype(int).to_numpy()\n",
    "year_mask = (years == years[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kinds = all_uniques['kind'].to_numpy()\n",
    "kind_mask = (kinds != kinds[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute intercommunity similarity\n",
    "\n",
    "We want communities that a) overlap in reltime, b) are from the same year, c) are of different kinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_norm_mean_embs = (all_mean_embs / np.linalg.norm(all_mean_embs, axis=1).reshape(-1, 1))\n",
    "all_sims = all_norm_mean_embs @ all_norm_mean_embs.T\n",
    "row_inds, col_inds = (time_mask & year_mask & kind_mask).nonzero()\n",
    "\n",
    "te = all_uniques.iloc[row_inds, :]\n",
    "te = te \\\n",
    "    [['year', 'kind', 'group', 'count', 'dur']] \\\n",
    "   .rename({'year': 'year1', 'kind': 'kind1', 'group': 'group1', 'count': 'count1', 'dur': 'dur1'}, axis=1) \\\n",
    "   .reset_index(drop=True)\n",
    "\n",
    "tc = all_uniques.iloc[col_inds, :]\n",
    "tc = tc \\\n",
    "    [['year', 'kind', 'group', 'count', 'dur']] \\\n",
    "   .rename({'year': 'year2', 'kind': 'kind2', 'group': 'group2', 'count': 'count2', 'dur': 'dur2'}, axis=1) \\\n",
    "   .reset_index(drop=True)\n",
    "\n",
    "matchable = pd.concat([te, tc], axis=1)\n",
    "matchable['sim'] = pd.Series(all_sims[row_inds, col_inds], index=matchable.index)\n",
    "\n",
    "assert matchable['year1'].isna().sum() == 0\n",
    "assert matchable['year2'].isna().sum() == 0\n",
    "matchable['year1'] = matchable['year1'].astype(int)\n",
    "matchable['year2'] = matchable['year2'].astype(int)\n",
    "assert (matchable['year1'] == matchable['year2']).all()\n",
    "\n",
    "matchable['story_id1'] = matchable['year1'].astype(str) + '-' + matchable['kind1'] + '-' + matchable['group1'].astype(str)\n",
    "matchable['story_id2'] = matchable['year2'].astype(str) + '-' + matchable['kind2'] + '-' + matchable['group2'].astype(str)\n",
    "\n",
    "matchable['count_ratio'] = matchable[['count1', 'count2']].max(axis=1) / matchable[['count1', 'count2']].min(axis=1)\n",
    "matchable['dur_ratio'] = matchable[['dur1', 'dur2']].max(axis=1) / matchable[['dur1', 'dur2']].min(axis=1)\n",
    "\n",
    "# deduplicate\n",
    "matchable = matchable.loc[matchable['story_id1'] < matchable['story_id2'], :]\n",
    "\n",
    "matchable = matchable.set_index(['story_id1', 'story_id2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matchable.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matchable['sim'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matchable['sim'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matchable['sim'].hist(by=[matchable['kind1'], matchable['kind2']], bins=50, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matchable['sim'].hist(by=[matchable['year1'], matchable['kind1'], matchable['kind2']], bins=50, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_story_size = 30\n",
    "count_ratio_max = 7\n",
    "dur_ratio_max = 3\n",
    "sim_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## elite $\\times$ radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_matchable = matchable.loc[\n",
    "    (matchable['kind1'] != 'decahose') &\n",
    "    (matchable['kind2'] != 'decahose') &\n",
    "    \n",
    "    (matchable['count1'] >= min_story_size) &\n",
    "    (matchable['count2'] >= min_story_size) &\n",
    "    \n",
    "   (matchable['count_ratio'] <= count_ratio_max) &\n",
    "   (matchable['dur_ratio'] <= dur_ratio_max),\n",
    ":].reset_index()\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    tmp_matchable,\n",
    "    source='story_id1',\n",
    "    target='story_id2',\n",
    "    edge_attr='sim',\n",
    "    create_using=nx.Graph\n",
    ")\n",
    "\n",
    "er_matched = list(nx.max_weight_matching(G, weight='sim'))\n",
    "\n",
    "er_matched = pd.DataFrame(\n",
    "    [[s[0]] + [s[1]] for s in er_matched] +\n",
    "    [[s[1]] + [s[0]] for s in er_matched],\n",
    "    \n",
    "    columns=['story_id1', 'story_id2'],\n",
    ")\n",
    "\n",
    "er_matched = er_matched.loc[er_matched['story_id1'] < er_matched['story_id2'], :]\n",
    "er_matched = matchable.reset_index().merge(er_matched, how='inner', on=['story_id1', 'story_id2'])\n",
    "\n",
    "er_matched = er_matched.rename({\n",
    "    'story_id1': 'story_id_elite',\n",
    "    'year1': 'year_elite',\n",
    "    'kind1': 'kind_elite',\n",
    "    'group1': 'group_elite',\n",
    "    'count1': 'count_elite',\n",
    "    'dur1': 'dur_elite',\n",
    "    \n",
    "    'story_id2': 'story_id_radio',\n",
    "    'year2': 'year_radio',\n",
    "    'kind2': 'kind_radio',\n",
    "    'group2': 'group_radio',\n",
    "    'count2': 'count_radio',\n",
    "    'dur2': 'dur_radio',\n",
    "    \n",
    "    'sim': 'sim_elite_radio',\n",
    "    'count_ratio': 'count_ratio_elite_radio',\n",
    "    'dur_ratio': 'dur_ratio_elite_radio',\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (elite $\\times$ radio) $\\times$ decahose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_matchable = matchable.loc[\n",
    "    (\n",
    "        (\n",
    "            matchable.index.get_level_values(0).isin(er_matched['story_id_elite']) |\n",
    "            matchable.index.get_level_values(0).isin(er_matched['story_id_radio'])\n",
    "        ) &\n",
    "        (matchable['kind2'] == 'decahose') &\n",
    "        (matchable['count2'] >= min_story_size) &\n",
    "        (matchable['count_ratio'] <= count_ratio_max) &\n",
    "        (matchable['dur_ratio'] <= dur_ratio_max)\n",
    "    ) |\n",
    "    (\n",
    "        (\n",
    "            matchable.index.get_level_values(1).isin(er_matched['story_id_elite']) |\n",
    "            matchable.index.get_level_values(1).isin(er_matched['story_id_radio'])\n",
    "        ) &\n",
    "        (matchable['kind1'] == 'decahose') &\n",
    "        (matchable['count1'] >= min_story_size) &\n",
    "        (matchable['count_ratio'] <= count_ratio_max) &\n",
    "        (matchable['dur_ratio'] <= dur_ratio_max)\n",
    "    ),\n",
    ":].reset_index()\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    tmp_matchable,\n",
    "    source='story_id1',\n",
    "    target='story_id2',\n",
    "    edge_attr='sim',\n",
    "    create_using=nx.Graph\n",
    ")\n",
    "\n",
    "dh_matched = list(nx.max_weight_matching(G, weight='sim'))\n",
    "\n",
    "dh_matched = pd.DataFrame(\n",
    "    [[s[0]] + [s[1]] for s in dh_matched] +\n",
    "    [[s[1]] + [s[0]] for s in dh_matched],\n",
    "    \n",
    "    columns=['story_id1', 'story_id2'],\n",
    ")\n",
    "\n",
    "dh_matched = dh_matched.loc[dh_matched['story_id1'] < dh_matched['story_id2'], :]\n",
    "dh_matched = matchable.reset_index().merge(dh_matched, how='inner', on=['story_id1', 'story_id2'])\n",
    "\n",
    "dh_matched = dh_matched.drop(['year2', 'kind2', 'group2', 'count2', 'dur2'], axis=1)\n",
    "dh_matched = dh_matched.rename({\n",
    "    'story_id1': 'story_id_decahose',\n",
    "    'year1': 'year_decahose',\n",
    "    'kind1': 'kind_decahose',\n",
    "    'group1': 'group_decahose',\n",
    "    'count1': 'count_decahose',\n",
    "    'dur1': 'dur_decahose',\n",
    "    \n",
    "    'story_id2': 'story_id_other',\n",
    "    'sim': 'sim_decahose_other',\n",
    "    'count_ratio': 'count_ratio_decahose_other',\n",
    "    'dur_ratio': 'dur_ratio_decahose_other',\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = pd.concat([\n",
    "    er_matched\n",
    "        .merge(dh_matched, how='left', left_on='story_id_elite', right_on='story_id_other'),\n",
    "    \n",
    "    er_matched\n",
    "        .merge(dh_matched, how='left', left_on='story_id_radio', right_on='story_id_other')\n",
    "], axis=0)\n",
    "\n",
    "matched['sim_decahose_other'] = matched['sim_decahose_other'].fillna(-np.inf)\n",
    "matched = matched.iloc[matched.groupby(['story_id_elite', 'story_id_radio'])['sim_decahose_other'].idxmax(), :]\n",
    "matched['sim_decahose_other'] = matched['sim_decahose_other'].replace(-np.inf, np.nan)\n",
    "\n",
    "assert (matched['kind_elite'] == 'elite').all()\n",
    "assert (matched['kind_radio'] == 'radio').all()\n",
    "assert ((matched['kind_decahose'] == 'decahose') | matched['kind_decahose'].isna()).all()\n",
    "assert (matched['year_elite'] == matched['year_radio']).all()\n",
    "assert ((matched['year_elite'] == matched['year_decahose']) | matched['year_decahose'].isna()).all()\n",
    "\n",
    "matched = matched.drop(['kind_elite', 'kind_radio', 'kind_decahose', 'year_radio', 'year_decahose'], axis=1)\n",
    "matched = matched.rename({'year_elite': 'year', 'story_id_other': 'story_id_decahose_matched'}, axis=1)\n",
    "\n",
    "matched = matched.sample(frac=1)\n",
    "matched = matched.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.groupby('year').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.groupby([\n",
    "    (matched['sim_elite_radio'] >= sim_threshold),\n",
    "    (matched['sim_decahose_other'] >= sim_threshold)\n",
    "]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = matched.loc[\n",
    "    (\n",
    "        (matched['sim_elite_radio'] >= sim_threshold) &\n",
    "        (matched['sim_decahose_other'] >= sim_threshold)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-audit some selected stories\n",
    "\n",
    "They should be about news and they are. Note we randomly sorted the selected stories; the first few are a random sample of all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf_query_end and cdf_query_inc are as also defined in the 5a notebook which calculates the cdfs\n",
    "def show_example(year, kind, group_ids, cdf_query_end=2*24*3600, cdf_query_inc=60):\n",
    "    if isinstance(group_ids, int):\n",
    "        group_ids = [group_ids]\n",
    "    \n",
    "    tmp = dat.loc[(dat['year'] == year) & (dat['kind'] == kind) & dat['group'].isin(group_ids), :].copy()\n",
    "    tmp['reltime'] -= tmp['reltime'].min()\n",
    "\n",
    "    cdf_query_pts = np.arange(0, cdf_query_end, cdf_query_inc)\n",
    "    cdf = ECDF(tmp['reltime'])(cdf_query_pts)\n",
    "    pdf = np.gradient(cdf)\n",
    "\n",
    "    with pd.option_context('display.max_colwidth', 0):\n",
    "        print(f'year: {year}, kind: {kind}, group id(s): ' + ','.join(str(c) for c in group_ids))\n",
    "        print('number of items: ' + str(tmp.shape[0]))\n",
    "        display(tmp.sample(min(tmp.shape[0], 10)))\n",
    "        # display(tmp.head(min(tmp.shape[0], 10)))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))    \n",
    "    tmp.loc[tmp['reltime'] <= tmp['reltime'].min() + cdf_query_end, :].hist('timestamp', ax=axes[0], xrot=45)\n",
    "\n",
    "    axes[1].plot(cdf_query_pts, cdf)\n",
    "    axes[2].plot(cdf_query_pts, pdf)\n",
    "\n",
    "    axes[0].set_title('Item times')\n",
    "    axes[1].set_title('ECDF')\n",
    "    axes[2].set_title('EPDF')\n",
    "\n",
    "    fmt = mp.ticker.FuncFormatter(lambda x, pos: f'{x / 3600:.0f}h')\n",
    "    axes[1].xaxis.set_major_formatter(fmt)\n",
    "    axes[2].xaxis.set_major_formatter(fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(matched.iloc[i, :]['sim_elite_radio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_example(\n",
    "    int(matched.iloc[i, :]['year']),\n",
    "    'elite',\n",
    "    int(matched.iloc[i, :]['group_elite']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_example(\n",
    "    int(matched.iloc[i, :]['year']),\n",
    "    'radio',\n",
    "    int(matched.iloc[i, :]['group_radio']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the selected stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched.to_csv('data/paper-round-3/event-annotated/auto-sample-communities-matching.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
