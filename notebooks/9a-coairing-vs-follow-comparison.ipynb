{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import logging\n",
    "import functools as ft\n",
    "\n",
    "import psycopg2\n",
    "import community\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import utils as ut\n",
    "\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "fmt = '%(asctime)s : %(levelname)s : %(message)s'\n",
    "logging.basicConfig(format=fmt, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/github/masthesis/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_show_orig = pd.read_csv('data/samples/twitter/user-show.csv')\n",
    "display(user_show_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('data/samples/twitter/user-data.csv', index_col='user_id')\n",
    "display(user_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_comm = pd.read_csv('data/twitter/community-ideology-by-show.csv')\n",
    "follow_comm = follow_comm.rename({'community': 'follow_community'}, axis=1)\n",
    "follow_comm = follow_comm.set_index('show_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter graphs\n",
    "\n",
    "These are the quotient graphs under the equivalence relation of being affiliated with the same radio show. Users not affiliated with a show are not equivalent to any other user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_user = pd.read_csv('data/twitter/community/quotient-follow-graph.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "fg_user = fg_user.drop('edge_attr', axis=1)\n",
    "\n",
    "fg_user = nx.from_pandas_edgelist(fg_user, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_user = pd.read_csv('data/twitter/community/quotient-mention-graph.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "mg_user = mg_user.drop('edge_attr', axis=1)\n",
    "\n",
    "mg_user = nx.from_pandas_edgelist(mg_user, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_user = pd.read_csv('data/twitter/community/quotient-retweet-graph.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "rg_user = rg_user.drop('edge_attr', axis=1)\n",
    "\n",
    "rg_user = nx.from_pandas_edgelist(rg_user, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_show = pd.read_csv('data/twitter/community/quotient-follow-graph-by-show.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "fg_show = fg_show.drop('edge_attr', axis=1)\n",
    "\n",
    "fg_show = nx.from_pandas_edgelist(fg_show, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_show = pd.read_csv('data/twitter/community/quotient-mention-graph-by-show.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "mg_show = mg_show.drop('edge_attr', axis=1)\n",
    "\n",
    "mg_show = nx.from_pandas_edgelist(mg_show, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_show = pd.read_csv('data/twitter/community/quotient-retweet-graph-by-show.csv',\n",
    "                      names=['source', 'target', 'edge_attr'])\n",
    "rg_show = rg_show.drop('edge_attr', axis=1)\n",
    "\n",
    "rg_show = nx.from_pandas_edgelist(rg_show, source='source', target='target',\n",
    "                                  edge_attr=None, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter show_ids and user_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to the shows we're using in main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_data = pd.read_csv('data/samples/radio/cooccurrence.csv')\n",
    "cg_show = nx.Graph(cooc_data.rename({'show_id1': 'source', 'show_id2': 'target'}, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/paper-round-3/radio/paper-round-3-snippets-audio-keys.csv.gz', 'rt') as f:\n",
    "    snippets_2019_2020 = pd.read_csv(f, index_col='snippet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/paper-round-3/radio/paper-round-3-snippets-show-station.csv.gz', 'rt') as f:\n",
    "    snippets_2019_2020_show_station = pd.read_csv(f, index_col='snippet_id')\n",
    "snippets_2019_2020['show_id'] = snippets_2019_2020_show_station['show_id']\n",
    "assert snippets_2019_2020['show_id'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_2019_2020['start_dt'] = pd.to_datetime(snippets_2019_2020['start_dt'])\n",
    "snippets_2019_2020['end_dt'] = pd.to_datetime(snippets_2019_2020['end_dt'])\n",
    "\n",
    "snippets_2019_2020['start_dt'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows_old = pd.concat([cooc_data['show_id1'], cooc_data['show_id2']]).unique().tolist()\n",
    "shows_new = snippets_2019_2020['show_id'].unique().tolist()\n",
    "shows_missing = set(shows_old) - set(shows_new)\n",
    "assert set(shows_new) - set(shows_old) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del snippets_2019_2020, snippets_2019_2020_show_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_show = user_show_orig.loc[user_show_orig['show_id'].isin(shows_new)]\n",
    "follow_comm = follow_comm.loc[follow_comm.index.isin(shows_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_names = user_show[['show_id', 'show_name']] \\\n",
    "                      .drop_duplicates() \\\n",
    "                      .sort_values(by='show_id') \\\n",
    "                      .set_index('show_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_show = cg_show.subgraph(shows_new).copy()\n",
    "fg_show = fg_show.subgraph(shows_new).copy()\n",
    "mg_show = mg_show.subgraph(shows_new).copy()\n",
    "rg_show = rg_show.subgraph(shows_new).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = user_show.show_id.isin(fg_show) & user_show.show_id.isin(cg_show) & user_show.user_id.isin(fg_user)\n",
    "\n",
    "radio_user_ids = user_show.loc[mask, 'user_id'].unique().tolist()\n",
    "radio_show_ids = user_show.loc[mask, 'show_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgr_show = cg_show.subgraph(radio_show_ids).copy()\n",
    "fgr_show = fg_show.subgraph(radio_show_ids).copy()\n",
    "mgr_show = mg_show.subgraph(radio_show_ids).copy()\n",
    "rgr_show = rg_show.subgraph(radio_show_ids).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop self-loop edges and isolates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-loops\n",
    "\n",
    "Drop these first so that any nodes with only self edges are dropped as isolates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(nx.selfloop_edges(fgr_show))\n",
    "fgr_show.remove_edges_from(edges)\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(nx.selfloop_edges(mgr_show))\n",
    "mgr_show.remove_edges_from(edges)\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(nx.selfloop_edges(rgr_show))\n",
    "rgr_show.remove_edges_from(edges)\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(nx.selfloop_edges(cgr_show))\n",
    "cgr_show.remove_edges_from(edges)\n",
    "\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = set(list(nx.isolates(fgr_show)))\n",
    "fgr_show.remove_nodes_from(isolates)\n",
    "\n",
    "len(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = set(list(nx.isolates(mgr_show)))\n",
    "mgr_show.remove_nodes_from(isolates)\n",
    "\n",
    "len(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = set(list(nx.isolates(rgr_show)))\n",
    "rgr_show.remove_nodes_from(isolates)\n",
    "\n",
    "len(isolates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = set(list(nx.isolates(cgr_show)))\n",
    "cgr_show.remove_nodes_from(isolates)\n",
    "\n",
    "len(isolates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = cg_show.order()\n",
    "size = cg_show.size()\n",
    "\n",
    "display(order)\n",
    "display(size)\n",
    "display(order * (order - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = cgr_show.order()\n",
    "size = cgr_show.size()\n",
    "\n",
    "display(order)\n",
    "display(size)\n",
    "display(order * (order - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = fgr_show.order()\n",
    "size = fgr_show.size()\n",
    "\n",
    "display(order)\n",
    "display(size)\n",
    "display(order * (order - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = mgr_show.order()\n",
    "size = mgr_show.size()\n",
    "\n",
    "display(order)\n",
    "display(size)\n",
    "display(order * (order - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = rgr_show.order()\n",
    "size = rgr_show.size()\n",
    "\n",
    "display(order)\n",
    "display(size)\n",
    "display(order * (order - 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all possible edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sr = pd.Series(radio_show_ids, name='show_id')\n",
    "tmp_cd = pd.DataFrame(cgr_show.to_undirected().edges, columns=['show_id1', 'show_id2'])\n",
    "tmp_fd = pd.DataFrame(fgr_show.to_undirected().edges, columns=['show_id1', 'show_id2'])\n",
    "tmp_md = pd.DataFrame(mgr_show.to_undirected().edges, columns=['show_id1', 'show_id2'])\n",
    "tmp_rd = pd.DataFrame(rgr_show.to_undirected().edges, columns=['show_id1', 'show_id2'])\n",
    "\n",
    "dat_dyad = pysqldf('''\n",
    "with frame as\n",
    "(\n",
    "    select\n",
    "        us1.show_id as show_id1,\n",
    "        us2.show_id as show_id2\n",
    "    from tmp_sr us1\n",
    "        cross join tmp_sr us2\n",
    "    where\n",
    "        us1.show_id < us2.show_id\n",
    ")\n",
    "select\n",
    "    fr.show_id1,\n",
    "    fr.show_id2,\n",
    "    \n",
    "    (cda.show_id1 is not null or cdb.show_id1 is not null) as in_cg,\n",
    "    (fda.show_id1 is not null or fdb.show_id1 is not null) as in_fg,\n",
    "    (mda.show_id1 is not null or mdb.show_id1 is not null) as in_mg,\n",
    "    (rda.show_id1 is not null or rdb.show_id1 is not null) as in_rg\n",
    "from frame fr\n",
    "    left join tmp_cd cda on cda.show_id1 = fr.show_id1 and cda.show_id2 = fr.show_id2\n",
    "    left join tmp_cd cdb on cda.show_id1 = fr.show_id2 and cda.show_id2 = fr.show_id1\n",
    "    \n",
    "    left join tmp_fd fda on fda.show_id1 = fr.show_id1 and fda.show_id2 = fr.show_id2\n",
    "    left join tmp_fd fdb on fda.show_id1 = fr.show_id2 and fda.show_id2 = fr.show_id1\n",
    "    \n",
    "    left join tmp_md mda on mda.show_id1 = fr.show_id1 and mda.show_id2 = fr.show_id2\n",
    "    left join tmp_md mdb on mda.show_id1 = fr.show_id2 and mda.show_id2 = fr.show_id1\n",
    "\n",
    "    left join tmp_rd rda on rda.show_id1 = fr.show_id1 and rda.show_id2 = fr.show_id2\n",
    "    left join tmp_rd rdb on rda.show_id1 = fr.show_id2 and rda.show_id2 = fr.show_id1\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat_dyad.in_cg, dat_dyad.in_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat_dyad.in_cg, dat_dyad.in_fg, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat_dyad.in_cg, dat_dyad.in_fg, normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot co-airing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [x for x in nx.connected_components(cg_show)]\n",
    "\n",
    "pd.Series([len(x) for x in comps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "am = np.argmax([len(x) for x in comps])\n",
    "\n",
    "nx.draw_spring(cg_show.subgraph(comps[am]), node_size=50, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare co-airing and follow / mention graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_fg = pd.DataFrame(list(fgr_show.to_undirected().degree()), columns=['name', 'degree'])\n",
    "deg_mg = pd.DataFrame(list(mgr_show.to_undirected().degree()), columns=['name', 'degree'])\n",
    "deg_cg = pd.DataFrame(list(cgr_show.degree()), columns=['name', 'degree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "deg_fg.boxplot('degree', ax=axes[0])\n",
    "deg_mg.boxplot('degree', ax=axes[1])\n",
    "deg_cg.boxplot('degree', ax=axes[2])\n",
    "\n",
    "axes[0].set_title('Follow degree')\n",
    "axes[1].set_title('Mention degree')\n",
    "axes[2].set_title('Co-airing degree')\n",
    "\n",
    "axes[0].set_ylim(-2, 40)\n",
    "axes[1].set_ylim(-2, 40)\n",
    "axes[2].set_ylim(-2, 40)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "deg_fg.boxplot('degree', ax=axes[0])\n",
    "deg_cg.boxplot('degree', ax=axes[1])\n",
    "\n",
    "axes[0].set_title('Co-airing degree')\n",
    "axes[1].set_title('Follow degree')\n",
    "\n",
    "axes[0].set_ylim(-2, 40)\n",
    "axes[1].set_ylim(-2, 40)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_fg['degree'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_mg['degree'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_cg['degree'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(fgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(mgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.transitivity(cgr_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(fgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(mgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(cgr_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(fgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(mgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.is_connected(cgr_show.to_undirected())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual-level measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_indiv_user = user_show.loc[user_show.user_id.isin(radio_user_ids), 'user_id']\n",
    "dat_indiv_user = pd.Series(dat_indiv_user, name='user_id')\n",
    "dat_indiv_user = pd.DataFrame(dat_indiv_user)\n",
    "\n",
    "dat_indiv_user.loc[:, 'follow_indegree'] = dat_indiv_user.user_id.map(dict(fg_user.in_degree()))\n",
    "dat_indiv_user.loc[:, 'mention_indegree'] = dat_indiv_user.user_id.map(dict(mg_user.in_degree()))\n",
    "dat_indiv_user.loc[:, 'retweet_indegree'] = dat_indiv_user.user_id.map(dict(rg_user.in_degree()))\n",
    "dat_indiv_user.loc[:, 'follow_outdegree'] = dat_indiv_user.user_id.map(dict(fg_user.out_degree()))\n",
    "dat_indiv_user.loc[:, 'mention_outdegree'] = dat_indiv_user.user_id.map(dict(mg_user.out_degree()))\n",
    "dat_indiv_user.loc[:, 'retweet_outdegree'] = dat_indiv_user.user_id.map(dict(rg_user.out_degree()))\n",
    "dat_indiv_user.loc[:, 'follow_pagerank'] = dat_indiv_user.user_id.map(dict(nx.pagerank(fg_user)))\n",
    "dat_indiv_user.loc[:, 'mention_pagerank'] = dat_indiv_user.user_id.map(dict(nx.pagerank(mg_user)))\n",
    "dat_indiv_user.loc[:, 'retweet_pagerank'] = dat_indiv_user.user_id.map(dict(nx.pagerank(rg_user)))\n",
    "dat_indiv_user.loc[:, 'follow_clustering'] = dat_indiv_user.user_id.map(dict(nx.clustering(fg_user)))\n",
    "dat_indiv_user.loc[:, 'mention_clustering'] = dat_indiv_user.user_id.map(dict(nx.clustering(mg_user)))\n",
    "dat_indiv_user.loc[:, 'retweet_clustering'] = dat_indiv_user.user_id.map(dict(nx.clustering(rg_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_indiv_show = dat_indiv_user.merge(user_show[['user_id', 'show_id']], how='inner', on='user_id')\n",
    "\n",
    "dat_indiv_show.loc[:, 'cooccurrence_degree'] = dat_indiv_show.show_id.map(dict(cg_show.degree()))\n",
    "dat_indiv_show.loc[:, 'cooccurrence_pagerank'] = dat_indiv_show.show_id.map(dict(nx.pagerank(cg_show)))\n",
    "dat_indiv_show.loc[:, 'cooccurrence_clustering'] = dat_indiv_show.show_id.map(dict(nx.clustering(cg_show)))\n",
    "\n",
    "dat_indiv_show = dat_indiv_show.set_index('show_id')\n",
    "\n",
    "display(dat_indiv_show.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_indiv_show.corr()[['cooccurrence_degree', 'cooccurrence_pagerank', 'cooccurrence_clustering']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community\n",
    "\n",
    "Louvain communities in the coairing graph, vs the previously computed Louvain communities in the follow graph (ignoring edge directions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms = follow_comm.copy()\n",
    "\n",
    "qpartition = community.best_partition(cg_show)\n",
    "qpartition = pd.Series(qpartition, name='community')\n",
    "\n",
    "comms['cooccurrence_community'] = qpartition\n",
    "comms = comms.loc[~comms.cooccurrence_community.isna(), :]\n",
    "\n",
    "display(comms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(comms.follow_community, comms.cooccurrence_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(comms.mention_community, comms.cooccurrence_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(comms.follow_community == 3, comms.cooccurrence_community == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(comms.mention_community == 2, comms.cooccurrence_community == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate configuration model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13893224121\n",
    "\n",
    "# n = cgr_show.order()\n",
    "# p = cgr_show.size() / ((n - 1)**2 / 2)\n",
    "# g1 = nx.erdos_renyi_graph(n=n, p=p, directed=False)\n",
    "g1 = nx.configuration_model([s[1] for s in cgr_show.degree()], seed=seed)\n",
    "\n",
    "# n = fgr_show.order()\n",
    "# p = fgr_show.size() / ((n - 1)**2 / 2)\n",
    "# g2 = nx.erdos_renyi_graph(n=n, p=p, directed=False)\n",
    "g2 = nx.configuration_model([s[1] for s in fgr_show.to_undirected().degree()], seed=seed)\n",
    "\n",
    "for graph in [g1, g2, cgr_show, fgr_show, mgr_show, rgr_show]:\n",
    "    for n in graph.nodes:\n",
    "        graph.nodes[n]['show_id'] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approx edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 30\n",
    "node_match = lambda g1, g2: g1['show_id'] == g2['show_id']\n",
    "\n",
    "edit_dists = {\n",
    "    'random': nx.graph_edit_distance(g1, g2, node_match=node_match, timeout=timeout),\n",
    "    'follow_directed': nx.graph_edit_distance(fgr_show, cgr_show, node_match=node_match, timeout=timeout),\n",
    "    'follow_undirected': nx.graph_edit_distance(fgr_show.to_undirected(), cgr_show, node_match=node_match, timeout=timeout),\n",
    "    'mention_directed': nx.graph_edit_distance(mgr_show, cgr_show, node_match=node_match, timeout=timeout),\n",
    "    'mention_undirected': nx.graph_edit_distance(mgr_show.to_undirected(), cgr_show, node_match=node_match, timeout=timeout),\n",
    "}\n",
    "\n",
    "edit_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simrank similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = nx.simrank_similarity(cgr_show)\n",
    "cs = pd.DataFrame.from_records(cs)\n",
    "cs = pd.melt(cs, ignore_index=False).reset_index().rename({'variable': 'show_id1', 'index': 'show_id2'}, axis=1)\n",
    "\n",
    "fs = nx.simrank_similarity(fgr_show.to_undirected())\n",
    "fs = pd.DataFrame.from_records(fs)\n",
    "fs = pd.melt(fs, ignore_index=False).reset_index().rename({'variable': 'show_id1', 'index': 'show_id2'}, axis=1)\n",
    "\n",
    "ms = nx.simrank_similarity(mgr_show.to_undirected())\n",
    "ms = pd.DataFrame.from_records(ms)\n",
    "ms = pd.melt(ms, ignore_index=False).reset_index().rename({'variable': 'show_id1', 'index': 'show_id2'}, axis=1)\n",
    "\n",
    "g1s = nx.simrank_similarity(g1)\n",
    "g1s = pd.DataFrame.from_records(g1s)\n",
    "g1s = pd.melt(g1s, ignore_index=False).reset_index().rename({'variable': 'show_id1', 'index': 'show_id2'}, axis=1)\n",
    "\n",
    "g2s = nx.simrank_similarity(g2)\n",
    "g2s = pd.DataFrame.from_records(g2s)\n",
    "g2s = pd.melt(g2s, ignore_index=False).reset_index().rename({'variable': 'show_id1', 'index': 'show_id2'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random graph baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = g2s.merge(g1s, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'g2', 'value_y': 'g1'}, axis=1)\n",
    "dat = dat.loc[dat['show_id1'] > dat['show_id2'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['g1', 'g2']].corr().loc['g1', 'g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat['g1'] - dat['g2']).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dat['g1'], dat['g2'], s=5, alpha=0.75, c='navy', lw=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simrank similarities: follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = fs.merge(cs, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'fs', 'value_y': 'cs'}, axis=1)\n",
    "dat = dat.loc[dat['show_id1'] > dat['show_id2'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['fs', 'cs']].corr().loc['fs', 'cs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat['fs'] - dat['cs']).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dat['fs'], dat['cs'], s=5, alpha=0.75, c='navy', lw=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('''\n",
    "select\n",
    "    sn1.show_name,\n",
    "    sn2.show_name,\n",
    "    dat.fs,\n",
    "    dat.cs\n",
    "from dat\n",
    "    inner join show_names sn1 on sn1.show_id = dat.show_id1\n",
    "    inner join show_names sn2 on sn2.show_id = dat.show_id2\n",
    "where\n",
    "    dat.cs < 0.15\n",
    "order by random()\n",
    "limit 20;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('''\n",
    "select\n",
    "    sn1.show_name,\n",
    "    sn2.show_name,\n",
    "    dat.fs,\n",
    "    dat.cs\n",
    "from dat\n",
    "    inner join show_names sn1 on sn1.show_id = dat.show_id1\n",
    "    inner join show_names sn2 on sn2.show_id = dat.show_id2\n",
    "where\n",
    "    dat.cs > 0.15\n",
    "order by random()\n",
    "limit 20;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simrank similarities: mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = ms.merge(cs, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'ms', 'value_y': 'cs'}, axis=1)\n",
    "dat = dat.loc[dat['show_id1'] > dat['show_id2'], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[['ms', 'cs']].corr().loc['ms', 'cs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat['ms'] - dat['cs']).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(dat['ms'], dat['cs'], s=5, alpha=0.75, c='navy', lw=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('''\n",
    "select\n",
    "    sn1.show_name,\n",
    "    sn2.show_name,\n",
    "    dat.ms,\n",
    "    dat.cs\n",
    "from dat\n",
    "    inner join show_names sn1 on sn1.show_id = dat.show_id1\n",
    "    inner join show_names sn2 on sn2.show_id = dat.show_id2\n",
    "where\n",
    "    dat.cs < 0.15\n",
    "order by random()\n",
    "limit 20;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf('''\n",
    "select\n",
    "    sn1.show_name,\n",
    "    sn2.show_name,\n",
    "    dat.ms,\n",
    "    dat.cs\n",
    "from dat\n",
    "    inner join show_names sn1 on sn1.show_id = dat.show_id1\n",
    "    inner join show_names sn2 on sn2.show_id = dat.show_id2\n",
    "where\n",
    "    dat.cs > 0.15\n",
    "order by random()\n",
    "limit 20;\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_dists = ft.reduce(lambda x, y: x + y, [\n",
    "    [(source, target, distance) for target, distance in targets.items()]\n",
    "    for source, targets in list(nx.shortest_path_length(g1))\n",
    "])\n",
    "g1_dists = pd.DataFrame.from_records(g1_dists, columns=['show_id1', 'show_id2', 'dist'])\n",
    "g1_dists = g1_dists.loc[g1_dists.show_id1 > g1_dists.show_id2, :]\n",
    "\n",
    "g2_dists = ft.reduce(lambda x, y: x + y, [\n",
    "    [(source, target, distance) for target, distance in targets.items()]\n",
    "    for source, targets in list(nx.shortest_path_length(g2))\n",
    "])\n",
    "g2_dists = pd.DataFrame.from_records(g2_dists, columns=['show_id1', 'show_id2', 'dist'])\n",
    "g2_dists = g2_dists.loc[g2_dists.show_id1 > g2_dists.show_id2, :]\n",
    "\n",
    "cgr_dists = ft.reduce(lambda x, y: x + y, [\n",
    "    [(source, target, distance) for target, distance in targets.items()]\n",
    "    for source, targets in list(nx.shortest_path_length(cgr_show))\n",
    "])\n",
    "cgr_dists = pd.DataFrame.from_records(cgr_dists, columns=['show_id1', 'show_id2', 'dist'])\n",
    "cgr_dists = cgr_dists.loc[cgr_dists.show_id1 > cgr_dists.show_id2, :]\n",
    "\n",
    "fgr_dists = ft.reduce(lambda x, y: x + y, [\n",
    "    [(source, target, distance) for target, distance in targets.items()]\n",
    "    for source, targets in list(nx.shortest_path_length(fgr_show.to_undirected()))\n",
    "])\n",
    "fgr_dists = pd.DataFrame.from_records(fgr_dists, columns=['show_id1', 'show_id2', 'dist'])\n",
    "fgr_dists = fgr_dists.loc[fgr_dists.show_id1 > fgr_dists.show_id2, :]\n",
    "\n",
    "mgr_dists = ft.reduce(lambda x, y: x + y, [\n",
    "    [(source, target, distance) for target, distance in targets.items()]\n",
    "    for source, targets in list(nx.shortest_path_length(mgr_show.to_undirected()))\n",
    "])\n",
    "mgr_dists = pd.DataFrame.from_records(mgr_dists, columns=['show_id1', 'show_id2', 'dist'])\n",
    "mgr_dists = mgr_dists.loc[mgr_dists.show_id1 > mgr_dists.show_id2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = g1_dists.merge(g2_dists, how='inner', on=['show_id1', 'show_id2']).rename({'dist_x': 'g1', 'dist_y': 'g2'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.corr().loc['g1', 'g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat['g1'], dat['g2'], normalize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = fgr_dists.merge(cgr_dists, on=['show_id1', 'show_id2']).rename({'dist_x': 'fgr', 'dist_y': 'cgr'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.corr().loc['fgr', 'cgr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat['fgr'], dat['cgr'], normalize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = mgr_dists.merge(cgr_dists, on=['show_id1', 'show_id2']).rename({'dist_x': 'mgr', 'dist_y': 'cgr'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.corr().loc['mgr', 'cgr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dat['mgr'], dat['cgr'], normalize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect stats / plots used in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_show.order(), cg_show.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(c) for c in list(nx.connected_components(cg_show))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_show_orig['show_id'].nunique(), user_show_orig['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_show['show_id'].nunique(), user_show['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    ('follow', 'order'): fgr_show.to_undirected().order(),\n",
    "    ('follow', 'size'): fgr_show.to_undirected().size(),\n",
    "    ('follow', 'avg_degree'): pd.DataFrame(list(fgr_show.to_undirected().degree()), columns=['name', 'degree'])['degree'].mean(),\n",
    "    ('follow', 'transitivity'): nx.transitivity(fgr_show.to_undirected()),\n",
    "    ('follow', 'avg_clustering_coef'): nx.average_clustering(fgr_show.to_undirected()),\n",
    "\n",
    "    ('mention', 'order'): mgr_show.to_undirected().order(),\n",
    "    ('mention', 'size'): mgr_show.to_undirected().size(),\n",
    "    ('mention', 'avg_degree'): pd.DataFrame(list(mgr_show.to_undirected().degree()), columns=['name', 'degree'])['degree'].mean(),\n",
    "    ('mention', 'transitivity'): nx.transitivity(mgr_show.to_undirected()),\n",
    "    ('mention', 'avg_clustering_coef'): nx.average_clustering(mgr_show.to_undirected()),\n",
    "\n",
    "    ('coairing', 'order'): cgr_show.order(),\n",
    "    ('coairing', 'size'): cgr_show.size(),\n",
    "    ('coairing', 'avg_degree'): pd.DataFrame(list(cgr_show.degree()), columns=['name', 'degree'])['degree'].mean(),\n",
    "    ('coairing', 'transitivity'): nx.transitivity(cgr_show),\n",
    "    ('coairing', 'avg_clustering_coef'): nx.average_clustering(cgr_show),\n",
    "}\n",
    "\n",
    "stats = pd.DataFrame(pd.Series(stats)) \\\n",
    "    .reset_index() \\\n",
    "    .rename({'level_0': 'graph', 'level_1': 'statistic', 0: 'value'}, axis=1) \\\n",
    "    .set_index(['graph', 'statistic']) \\\n",
    "    .unstack(0) \\\n",
    "    .loc[['order', 'size', 'avg_degree', 'transitivity', 'avg_clustering_coef']]\n",
    "\n",
    "stats = stats.rename({\n",
    "    'order': r'Order (\\# nodes)',\n",
    "    'size': r'Size (\\# edges)',\n",
    "    'avg_degree': 'Average degree',\n",
    "    'transitivity': 'Transitivity',\n",
    "    'avg_clustering_coef': 'Avg. Clust. Coef.',\n",
    "}, axis=0)\n",
    "\n",
    "stats.columns = [c[1].title() for c in stats.columns]\n",
    "stats.index.name = stats.index.name.title()\n",
    "\n",
    "kwargs = {\n",
    "    'environment': 'table',\n",
    "    'label': 'tab:si-graph-metrics-follow-vs-coairing',\n",
    "    'position_float': 'centering',\n",
    "    'column_format': 'lccc',\n",
    "    \n",
    "    'caption': r'''\n",
    "    Selected summary statistics of the follow and coairing graphs for the set of Twitter-matched shows, demonstrating a substantial degree of similarity. Respectively 10 and 9 shows out of 67 have been excluded from the follow and coairing graph statistics shown here because they were isolates.\n",
    "    '''.strip(),\n",
    "    \n",
    "    'hrules': True,\n",
    "}\n",
    "\n",
    "print(stats \\\n",
    "    .style \\\n",
    "    .format(precision=2) \\\n",
    "    .to_latex(**kwargs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = g2s.merge(g1s, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'g2', 'value_y': 'g1'}, axis=1)\n",
    "df_baseline = df_baseline.loc[df_baseline['show_id1'] > df_baseline['show_id2'], :]\n",
    "\n",
    "df_follow = fs.merge(cs, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'fs', 'value_y': 'cs'}, axis=1)\n",
    "df_follow = df_follow.loc[df_follow['show_id1'] > df_follow['show_id2'], :]\n",
    "\n",
    "df_mention = ms.merge(cs, how='inner', on=['show_id1', 'show_id2']).rename({'value_x': 'ms', 'value_y': 'cs'}, axis=1)\n",
    "df_mention = df_mention.loc[df_mention['show_id1'] > df_mention['show_id2'], :]\n",
    "\n",
    "lineticks = np.linspace(0.12, 0.3, 1500)\n",
    "textbox_props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "ylim = (0.05, 0.35)\n",
    "xlim = (0.12, 0.32)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, constrained_layout=True, figsize=(15, 5))\n",
    "\n",
    "### Follow\n",
    "n_shows = len(set(df_follow['show_id1'].tolist() + df_follow['show_id1'].tolist()))\n",
    "x, y = df_follow['fs'], df_follow['cs']\n",
    "axes[0].scatter(x, y, s=5, alpha=0.75, c='navy', lw=0.25)\n",
    "\n",
    "fit = np.poly1d(np.polyfit(x, y, 1))\n",
    "axes[0].plot(lineticks, fit(lineticks)) # best-fit line\n",
    "\n",
    "r, r2 = x.corr(y), x.corr(y) ** 2\n",
    "txt = f'$r^2 = {r2.round(3)}$\\n$r = {r.round(3)}$\\nn = {n_shows} shows'\n",
    "axes[0].text(0.68, 0.18, txt, transform=axes[0].transAxes, fontsize=13,\n",
    "         verticalalignment='top', bbox=textbox_props)\n",
    "\n",
    "axes[0].set_title('Follow vs Coairing')\n",
    "axes[0].set_xlabel('SimRank: Follow')\n",
    "axes[0].set_ylabel('SimRank: Coairing')\n",
    "axes[0].tick_params(axis='x', labelrotation = 45)\n",
    "\n",
    "axes[0].set_ylim(*ylim)\n",
    "axes[0].set_xlim(*xlim)\n",
    "\n",
    "### Mention\n",
    "n_shows = len(set(df_mention['show_id1'].tolist() + df_mention['show_id1'].tolist()))\n",
    "x, y = df_mention['ms'], df_mention['cs']\n",
    "axes[1].scatter(x, y, s=5, alpha=0.75, c='navy', lw=0.25)\n",
    "\n",
    "fit = np.poly1d(np.polyfit(x, y, 1))\n",
    "axes[1].plot(lineticks, fit(lineticks)) # best-fit line\n",
    "\n",
    "r, r2 = x.corr(y), x.corr(y) ** 2\n",
    "txt = f'$r^2 = {r2.round(3)}$\\n$r = {r.round(3)}$\\nn = {n_shows} shows'\n",
    "axes[1].text(0.68, 0.18, txt, transform=axes[1].transAxes, fontsize=13,\n",
    "         verticalalignment='top', bbox=textbox_props)\n",
    "\n",
    "axes[1].set_title('Mention vs Coairing')\n",
    "axes[1].set_xlabel('SimRank: Mention')\n",
    "axes[1].set_ylabel('SimRank: Coairing')\n",
    "axes[1].tick_params(axis='x', labelrotation = 45)\n",
    "\n",
    "axes[1].set_ylim(*ylim)\n",
    "axes[1].set_xlim(*xlim)\n",
    "\n",
    "### Baseline\n",
    "n_shows = len(set(df_baseline['show_id1'].tolist() + df_baseline['show_id1'].tolist()))\n",
    "x, y = df_baseline['g1'], df_baseline['g2']\n",
    "axes[2].scatter(x, y, s=5, alpha=0.75, c='navy', lw=0.25)\n",
    "\n",
    "fit = np.poly1d(np.polyfit(x, y, 1))\n",
    "axes[2].plot(lineticks, fit(lineticks)) # best-fit line\n",
    "\n",
    "r, r2 = x.corr(y), x.corr(y) ** 2\n",
    "txt = f'$r^2 = {r2.round(3)}$\\n$r = {r.round(3)}$\\nn = {n_shows} shows'\n",
    "axes[2].text(0.68, 0.18, txt, transform=axes[2].transAxes, fontsize=13,\n",
    "         verticalalignment='top', bbox=textbox_props)\n",
    "\n",
    "axes[2].set_title('Baseline: Configuration Models')\n",
    "axes[2].set_xlabel('SimRank: Graph 1')\n",
    "axes[2].set_ylabel('SimRank: Graph 2')\n",
    "axes[2].tick_params(axis='x', labelrotation = 45)\n",
    "\n",
    "axes[2].set_ylim(*ylim)\n",
    "axes[2].set_xlim(*xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
